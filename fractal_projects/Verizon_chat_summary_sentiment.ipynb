{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verizon chat analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/akshay/Desktop/Fractal/NLP\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>engagement_id</th>\n",
       "      <th>scat_event_dt</th>\n",
       "      <th>nps_score</th>\n",
       "      <th>chat_agent_name</th>\n",
       "      <th>cust_cb_sentiment_score</th>\n",
       "      <th>agent_cb_sentiment_score</th>\n",
       "      <th>customer_chat_text</th>\n",
       "      <th>agent_chat_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.237730e+17</td>\n",
       "      <td>12/13/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rafzam Joni Abiog</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hello i would like to add/activate an old devi...</td>\n",
       "      <td>I?ll be happy to help you today! As a courtesy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.237730e+17</td>\n",
       "      <td>12/13/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ronald Duhon Iii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Is the website down? Is your website down It k...</td>\n",
       "      <td>Welcome to Verizon Wireless Sales Chat, I'll b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.237730e+17</td>\n",
       "      <td>12/13/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jhemeil Tesiorna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Why does a number in my call log come up as NN...</td>\n",
       "      <td>Hi, my name is Jamie. I am more than happy to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.237730e+17</td>\n",
       "      <td>12/13/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mary Sansom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>what is the galaxy note 9'XXXX storage capasit...</td>\n",
       "      <td>I?d be happy to see how I can assist you! With...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.237730e+17</td>\n",
       "      <td>12/13/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marcella Cook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello Jessica. Apparently there is an issue wi...</td>\n",
       "      <td>Welcome to Verizon Wireless Sales Chat, I'll b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  engagement_id scat_event_dt  nps_score    chat_agent_name  \\\n",
       "0           0   7.237730e+17    12/13/2018        NaN  Rafzam Joni Abiog   \n",
       "1           1   7.237730e+17    12/13/2018        NaN   Ronald Duhon Iii   \n",
       "2           2   7.237730e+17    12/13/2018        NaN   Jhemeil Tesiorna   \n",
       "3           3   7.237730e+17    12/13/2018        NaN        Mary Sansom   \n",
       "4           4   7.237730e+17    12/13/2018        NaN      Marcella Cook   \n",
       "\n",
       "   cust_cb_sentiment_score  agent_cb_sentiment_score  \\\n",
       "0                      NaN                       NaN   \n",
       "1                      NaN                       NaN   \n",
       "2                      NaN                       NaN   \n",
       "3                      NaN                       NaN   \n",
       "4                      NaN                       NaN   \n",
       "\n",
       "                                  customer_chat_text  \\\n",
       "0  hello i would like to add/activate an old devi...   \n",
       "1  Is the website down? Is your website down It k...   \n",
       "2  Why does a number in my call log come up as NN...   \n",
       "3  what is the galaxy note 9'XXXX storage capasit...   \n",
       "4  Hello Jessica. Apparently there is an issue wi...   \n",
       "\n",
       "                                     agent_chat_text  \n",
       "0  I?ll be happy to help you today! As a courtesy...  \n",
       "1  Welcome to Verizon Wireless Sales Chat, I'll b...  \n",
       "2  Hi, my name is Jamie. I am more than happy to ...  \n",
       "3  I?d be happy to see how I can assist you! With...  \n",
       "4  Welcome to Verizon Wireless Sales Chat, I'll b...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_chat=pd.read_csv('/Users/akshay/Desktop/Fractal/NLP/chat_table_2018_12_12to2018_12_13_v1.csv',)\n",
    "df_chat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                     0\n",
       "engagement_id                  0\n",
       "scat_event_dt                  0\n",
       "nps_score                   3000\n",
       "chat_agent_name              299\n",
       "cust_cb_sentiment_score     3000\n",
       "agent_cb_sentiment_score    3000\n",
       "customer_chat_text           642\n",
       "agent_chat_text              642\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chat.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                     0\n",
       "engagement_id                  0\n",
       "scat_event_dt                  0\n",
       "nps_score                   2358\n",
       "chat_agent_name                0\n",
       "cust_cb_sentiment_score     2358\n",
       "agent_cb_sentiment_score    2358\n",
       "customer_chat_text             0\n",
       "agent_chat_text                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chat1 = df_chat.dropna(axis=0, subset=['customer_chat_text'])\n",
    "df_chat1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/akshay/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "# import library\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import string\n",
    "import textblob as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    result=sent_tokenize(text,language='english')\n",
    "    result=tokenize(result,language='english')\n",
    "    return result\n",
    "\n",
    "#df_chat1['customer_clean']=df_chat1['customer_chat_text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# function for text preprocessing\n",
    "def text_processing(row):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', row['customer_chat_text']) # match all strings that start with a letter, the second means match all strings that contain a non-letter\n",
    "    review = review.lower() # lower case\n",
    "    review = review.split() # split words\n",
    "    wl = WordNetLemmatizer()  # bettwer way to remove suffix by keping meaning full words\n",
    "    # remove most common english words in sentece \n",
    "    #review = [wl.lemmatize(word) for word in review if not word in set(stopwords.words('english'))] # aslo stops most common english words such as a,an, the in ,on etc\n",
    "    review = [wl.lemmatize(word) for word in review]\n",
    "    #review = ' '.join(review)\n",
    "    return review\n",
    "\n",
    "df_chat1['customer_clean1']=df_chat1.apply(text_processing,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>engagement_id</th>\n",
       "      <th>scat_event_dt</th>\n",
       "      <th>nps_score</th>\n",
       "      <th>chat_agent_name</th>\n",
       "      <th>cust_cb_sentiment_score</th>\n",
       "      <th>agent_cb_sentiment_score</th>\n",
       "      <th>customer_chat_text</th>\n",
       "      <th>agent_chat_text</th>\n",
       "      <th>customer_clean1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.237730e+17</td>\n",
       "      <td>12/13/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rafzam Joni Abiog</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hello i would like to add/activate an old devi...</td>\n",
       "      <td>I?ll be happy to help you today! As a courtesy...</td>\n",
       "      <td>[hello, i, would, like, to, add, activate, an,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.237730e+17</td>\n",
       "      <td>12/13/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ronald Duhon Iii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Is the website down? Is your website down It k...</td>\n",
       "      <td>Welcome to Verizon Wireless Sales Chat, I'll b...</td>\n",
       "      <td>[is, the, website, down, is, your, website, do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.237730e+17</td>\n",
       "      <td>12/13/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jhemeil Tesiorna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Why does a number in my call log come up as NN...</td>\n",
       "      <td>Hi, my name is Jamie. I am more than happy to ...</td>\n",
       "      <td>[why, doe, a, number, in, my, call, log, come,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.237730e+17</td>\n",
       "      <td>12/13/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mary Sansom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>what is the galaxy note 9'XXXX storage capasit...</td>\n",
       "      <td>I?d be happy to see how I can assist you! With...</td>\n",
       "      <td>[what, is, the, galaxy, note, xxxx, storage, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.237730e+17</td>\n",
       "      <td>12/13/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marcella Cook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello Jessica. Apparently there is an issue wi...</td>\n",
       "      <td>Welcome to Verizon Wireless Sales Chat, I'll b...</td>\n",
       "      <td>[hello, jessica, apparently, there, is, an, is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  engagement_id scat_event_dt  nps_score    chat_agent_name  \\\n",
       "0           0   7.237730e+17    12/13/2018        NaN  Rafzam Joni Abiog   \n",
       "1           1   7.237730e+17    12/13/2018        NaN   Ronald Duhon Iii   \n",
       "2           2   7.237730e+17    12/13/2018        NaN   Jhemeil Tesiorna   \n",
       "3           3   7.237730e+17    12/13/2018        NaN        Mary Sansom   \n",
       "4           4   7.237730e+17    12/13/2018        NaN      Marcella Cook   \n",
       "\n",
       "   cust_cb_sentiment_score  agent_cb_sentiment_score  \\\n",
       "0                      NaN                       NaN   \n",
       "1                      NaN                       NaN   \n",
       "2                      NaN                       NaN   \n",
       "3                      NaN                       NaN   \n",
       "4                      NaN                       NaN   \n",
       "\n",
       "                                  customer_chat_text  \\\n",
       "0  hello i would like to add/activate an old devi...   \n",
       "1  Is the website down? Is your website down It k...   \n",
       "2  Why does a number in my call log come up as NN...   \n",
       "3  what is the galaxy note 9'XXXX storage capasit...   \n",
       "4  Hello Jessica. Apparently there is an issue wi...   \n",
       "\n",
       "                                     agent_chat_text  \\\n",
       "0  I?ll be happy to help you today! As a courtesy...   \n",
       "1  Welcome to Verizon Wireless Sales Chat, I'll b...   \n",
       "2  Hi, my name is Jamie. I am more than happy to ...   \n",
       "3  I?d be happy to see how I can assist you! With...   \n",
       "4  Welcome to Verizon Wireless Sales Chat, I'll b...   \n",
       "\n",
       "                                     customer_clean1  \n",
       "0  [hello, i, would, like, to, add, activate, an,...  \n",
       "1  [is, the, website, down, is, your, website, do...  \n",
       "2  [why, doe, a, number, in, my, call, log, come,...  \n",
       "3  [what, is, the, galaxy, note, xxxx, storage, c...  \n",
       "4  [hello, jessica, apparently, there, is, an, is...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chat1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec and fasttext\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "\n",
    "model_w2v = Word2Vec(sentences=df_chat1.customer_clean1, size=1000, window=5, min_count=2, workers=4, sg=0)\n",
    "#model_ft = FastText(sentences=df_chat1.customer_clean1, size=1000, window=5, min_count=2, workers=4,sg=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4030"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dictionary of words index pairs\n",
    "lst_w2v = model_w2v.wv.index2word\n",
    "dic_w2v = {ii: indx for indx, ii in enumerate(lst_w2v)}\n",
    "len(dic_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4030, 1000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_matrix=model_w2v.wv.syn0\n",
    "w2v_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer,TfidfTransformer\n",
    "\n",
    "# function for text preprocessing\n",
    "def text_processing(row):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', row['customer_chat_text']) # match all strings that start with a letter, the second means match all strings that contain a non-letter\n",
    "    review = review.lower() # lower case\n",
    "    review = review.split() # split words\n",
    "    wl = WordNetLemmatizer()  # bettwer way to remove suffix by keping meaning full words\n",
    "    # remove most common english words in sentece \n",
    "    #review = [wl.lemmatize(word) for word in review if not word in set(stopwords.words('english'))] # aslo stops most common english words such as a,an, the in ,on etc\n",
    "    review = [wl.lemmatize(word) for word in review]\n",
    "    review = ' '.join(review)\n",
    "    return review\n",
    "\n",
    "\n",
    "df_chat1['customer_clean2']=df_chat1.apply(text_processing,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer,TfidfTransformer\n",
    "\n",
    "#TF-IDF vectorization ( with bigram )\n",
    "#tf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "tf = TfidfVectorizer(ngram_range=(1, 1),vocabulary=dic_w2v)\n",
    "tf_matrix = tf.fit_transform(df_chat1.customer_clean2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['i', 'the', 'to', 'it', 'a', 'my', 'you', 'and', 'is', 'for',\n",
       "       ...\n",
       "       'qualifies', 'renews', 'postal', 'fsi', 'cache', 'bump', 'gendron',\n",
       "       'lodovico', 'oldani', 'rodella'],\n",
       "      dtype='object', length=4030)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features name\n",
    "lst_tfidf = tf.get_feature_names()\n",
    "x_df = pd.DataFrame(tf_matrix.toarray(), columns=lst_tfidf)\n",
    "x_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4030"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check both words and index are same in tfidf and word2vec output\n",
    "ff1 = [0 if lst_w2v[ii]==x_df.columns[ii] else 1 for ii in range(len(lst_w2v))]\n",
    "ff1.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2358, 4030)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_tf = np.asmatrix(tf_matrix.toarray())\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4030, 1000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_w2v=np.asmatrix(w2v_matrix)\n",
    "n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_w2v=m_tf*n_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2358, 1000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def cluster(text_encoded):\n",
    "    n_clusters = int(np.ceil(len(text_encoded)**0.5))\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans = kmeans.fit(text_encoded)\n",
    "    return kmeans\n",
    "\n",
    "df_chat['Customer_clean_cluster']=df_chat['Customer_clean_encoder'].apply(cluster)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
